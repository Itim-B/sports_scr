{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "import easyocr\n",
    "import os\n",
    "import re\n",
    "import editdistance\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from torchmetrics import WordErrorRate, CharErrorRate, MatchErrorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(cur_path, \"data/natation/\")\n",
    "\n",
    "dic_names = {}\n",
    "for file in os.listdir(data_path):\n",
    "    if file[-4:] == \".txt\":\n",
    "        with open(os.path.join(data_path, file), 'r') as f:\n",
    "            names = f.readlines()\n",
    "            for n in names:\n",
    "                complete_name = n.strip().split()[:-1]\n",
    "                last_name = complete_name[:-1]\n",
    "                first_name = complete_name[-1]\n",
    "                if len(last_name) == 1:\n",
    "                    last_name = ' '.join(complete_name[:-1])\n",
    "                    if last_name in dic_names:\n",
    "                        continue\n",
    "                    else:\n",
    "                        dic_names[last_name] = first_name\n",
    "                else:\n",
    "                    for ln in last_name:\n",
    "                        if ln in dic_names: # ISSUE IF NAME WITH DIFFERENT FIRDT NAMES\n",
    "                            continue\n",
    "                        else:\n",
    "                            dic_names[ln] = first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_predictions(raw_predictions):\n",
    "    return [pred[1] for pred in raw_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_last_name(prediction, dic_names, min_edit_distance=2):\n",
    "    pattern = r'[0-9]'\n",
    "    cprediction = re.sub(pattern, '', prediction.strip()).strip()\n",
    "    last_names = []\n",
    "    for comp in cprediction.split(' '):\n",
    "        for n in dic_names.keys():\n",
    "            if editdistance.eval(n, comp) <= min_edit_distance:\n",
    "                last_names.append(comp)\n",
    "    return last_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_of_interest(predictions, dic_names):\n",
    "    preds = []\n",
    "    for pred in predictions:\n",
    "        cpred = get_prediction_last_name(pred, dic_names)\n",
    "        if len(cpred) == 0:\n",
    "            continue\n",
    "        elif len(cpred) == 1:\n",
    "            preds.extend(cpred)\n",
    "        else:\n",
    "            cpred = ' '.join(cpred)\n",
    "            preds.append(cpred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(path):\n",
    "    ground_truth = []\n",
    "    pattern = r'[0-9]'\n",
    "    with open(path, \"r\") as f:\n",
    "        ground_truth.extend([re.sub(pattern, '', y.strip()).strip(':., ') for y in f.readlines()])\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_names_ground_truth(ground_truth):\n",
    "    return [' '.join(gt.split(' ')[:-1]) for gt in ground_truth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions_of_interest, last_names_ground_truth):\n",
    "    mers = {yhat: 0 for yhat in predictions_of_interest}\n",
    "    wers = {yhat: 0 for yhat in predictions_of_interest}\n",
    "    cers = {yhat: 0 for yhat in predictions_of_interest}\n",
    "\n",
    "    mer = MatchErrorRate()\n",
    "    wer = WordErrorRate()\n",
    "    cer = CharErrorRate()\n",
    "\n",
    "    for yhat in predictions_of_interest:\n",
    "        min_mer_error_rate = 1000\n",
    "        min_wer_error_rate = 1000\n",
    "        min_cer_error_rate = 1000\n",
    "        for y in last_names_ground_truth:\n",
    "            if mer(yhat, y) < min_mer_error_rate:\n",
    "                min_mer_error_rate = mer(yhat, y)\n",
    "            if wer(yhat, y) < min_wer_error_rate:\n",
    "                min_wer_error_rate = wer(yhat, y)\n",
    "            if cer(yhat, y) < min_cer_error_rate:\n",
    "                min_cer_error_rate = cer(yhat, y)\n",
    "        mers[yhat] = min_mer_error_rate.item()\n",
    "        wers[yhat] = min_wer_error_rate.item()\n",
    "        cers[yhat] = min_cer_error_rate.item()\n",
    "\n",
    "    return mers, wers, cers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_image(gt_path, im_path, dic_names):\n",
    "    ground_truth = get_ground_truth(gt_path)\n",
    "    last_names_ground_truth = get_last_names_ground_truth(ground_truth)\n",
    "\n",
    "    predictions = reformat_predictions(reader.readtext(im_path))\n",
    "    predictions = get_predictions_of_interest(predictions, dic_names)\n",
    "\n",
    "    return compute_metrics(predictions, last_names_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_metric(gt_path, im_path, dic_names):\n",
    "    ground_truth = get_ground_truth(gt_path)\n",
    "    ground_truth = get_last_names_ground_truth(ground_truth)\n",
    "\n",
    "    mers, wers, cers = compute_metrics_for_image(gt_path, im_path, dic_names)\n",
    "    global_mer = sum(mers.values())/len(ground_truth)\n",
    "    global_wer = sum(wers.values())/len(ground_truth)\n",
    "    global_cer = sum(cers.values())/len(ground_truth)\n",
    "    \n",
    "    return (global_mer + global_wer + global_cer) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tuples = [(f\"00000{i}.png\", f\"00000{i}.txt\") for i in range(10)]\n",
    "path_tuples.extend([(f\"0000{i}.png\", f\"0000{i}.txt\") for i in range(10, 15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_path, path_tuples, dic_names, roi_path='', clip_text_prompt='', clip_visual_prompt=''):\n",
    "    metric = []\n",
    "    for i in range(len(path_tuples)):\n",
    "        im_path = data_path + roi_path + clip_text_prompt + clip_visual_prompt + path_tuples[i][0]\n",
    "        gt_path = data_path + path_tuples[i][1]\n",
    "        metric.append(get_final_metric(gt_path, im_path, dic_names))\n",
    "    return sum(metric)/len(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.006104005200417"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(data_path, path_tuples, dic_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation de l'algorithme sur les ROI seulement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8494430720534117"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(data_path, path_tuples, dic_names, roi_path='ROI/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/Users/y.tahtah/Downloads/ecl_ocr/sports_scr/data/natation/ROI/CLIP_text_prompt/000014.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(data_path, path_tuples, dic_names, roi_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mROI/\u001b[39;49m\u001b[39m'\u001b[39;49m, clip_text_prompt\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCLIP_text_prompt/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(data_path, path_tuples, dic_names, roi_path, clip_text_prompt, clip_visual_prompt)\u001b[0m\n\u001b[1;32m      4\u001b[0m     im_path \u001b[39m=\u001b[39m data_path \u001b[39m+\u001b[39m roi_path \u001b[39m+\u001b[39m clip_text_prompt \u001b[39m+\u001b[39m clip_visual_prompt \u001b[39m+\u001b[39m path_tuples[i][\u001b[39m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m     gt_path \u001b[39m=\u001b[39m data_path \u001b[39m+\u001b[39m path_tuples[i][\u001b[39m1\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m     metric\u001b[39m.\u001b[39mappend(get_final_metric(gt_path, im_path, dic_names))\n\u001b[1;32m      7\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(metric)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(metric)\n",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m, in \u001b[0;36mget_final_metric\u001b[0;34m(gt_path, im_path, dic_names)\u001b[0m\n\u001b[1;32m      2\u001b[0m ground_truth \u001b[39m=\u001b[39m get_ground_truth(gt_path)\n\u001b[1;32m      3\u001b[0m ground_truth \u001b[39m=\u001b[39m get_last_names_ground_truth(ground_truth)\n\u001b[0;32m----> 5\u001b[0m mers, wers, cers \u001b[39m=\u001b[39m compute_metrics_for_image(gt_path, im_path, dic_names)\n\u001b[1;32m      6\u001b[0m global_mer \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(mers\u001b[39m.\u001b[39mvalues())\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(ground_truth)\n\u001b[1;32m      7\u001b[0m global_wer \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(wers\u001b[39m.\u001b[39mvalues())\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(ground_truth)\n",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m, in \u001b[0;36mcompute_metrics_for_image\u001b[0;34m(gt_path, im_path, dic_names)\u001b[0m\n\u001b[1;32m      2\u001b[0m ground_truth \u001b[39m=\u001b[39m get_ground_truth(gt_path)\n\u001b[1;32m      3\u001b[0m last_names_ground_truth \u001b[39m=\u001b[39m get_last_names_ground_truth(ground_truth)\n\u001b[0;32m----> 5\u001b[0m predictions \u001b[39m=\u001b[39m reformat_predictions(reader\u001b[39m.\u001b[39;49mreadtext(im_path))\n\u001b[1;32m      6\u001b[0m predictions \u001b[39m=\u001b[39m get_predictions_of_interest(predictions, dic_names)\n\u001b[1;32m      8\u001b[0m \u001b[39mreturn\u001b[39;00m compute_metrics(predictions, last_names_ground_truth)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaocr/lib/python3.9/site-packages/easyocr/easyocr.py:442\u001b[0m, in \u001b[0;36mReader.readtext\u001b[0;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadtext\u001b[39m(\u001b[39mself\u001b[39m, image, decoder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgreedy\u001b[39m\u001b[39m'\u001b[39m, beamWidth\u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, batch_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\\\n\u001b[1;32m    429\u001b[0m              workers \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, allowlist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, blocklist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, detail \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\\\n\u001b[1;32m    430\u001b[0m              rotation_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, paragraph \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, min_size \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m,\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m              threshold \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, bbox_min_score \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, bbox_min_size \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m, max_candidates \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m    437\u001b[0m              output_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstandard\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    438\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m    Parameters:\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39m    image: file path or numpy-array or a byte stream object\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     img, img_cv_grey \u001b[39m=\u001b[39m reformat_input(image)\n\u001b[1;32m    444\u001b[0m     horizontal_list, free_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetect(img, \n\u001b[1;32m    445\u001b[0m                                              min_size \u001b[39m=\u001b[39m min_size, text_threshold \u001b[39m=\u001b[39m text_threshold,\\\n\u001b[1;32m    446\u001b[0m                                              low_text \u001b[39m=\u001b[39m low_text, link_threshold \u001b[39m=\u001b[39m link_threshold,\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m                                              bbox_min_size \u001b[39m=\u001b[39m bbox_min_size, max_candidates \u001b[39m=\u001b[39m max_candidates\n\u001b[1;32m    453\u001b[0m                                              )\n\u001b[1;32m    454\u001b[0m     \u001b[39m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/condaocr/lib/python3.9/site-packages/easyocr/utils.py:699\u001b[0m, in \u001b[0;36mreformat_input\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    697\u001b[0m         img_cv_grey \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image, cv2\u001b[39m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[1;32m    698\u001b[0m         image \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(image)\n\u001b[0;32m--> 699\u001b[0m     img \u001b[39m=\u001b[39m loadImage(image)  \u001b[39m# can accept URL\u001b[39;00m\n\u001b[1;32m    700\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(image) \u001b[39m==\u001b[39m \u001b[39mbytes\u001b[39m:\n\u001b[1;32m    701\u001b[0m     nparr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(image, np\u001b[39m.\u001b[39muint8)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaocr/lib/python3.9/site-packages/easyocr/imgproc.py:12\u001b[0m, in \u001b[0;36mloadImage\u001b[0;34m(img_file)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloadImage\u001b[39m(img_file):\n\u001b[0;32m---> 12\u001b[0m     img \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mimread(img_file)           \u001b[39m# RGB order\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m: img \u001b[39m=\u001b[39m img[\u001b[39m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(img\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m : img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_GRAY2RGB)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaocr/lib/python3.9/site-packages/skimage/io/_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m         plugin \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtifffile\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[39mwith\u001b[39;00m file_or_url_context(fname) \u001b[39mas\u001b[39;00m fname:\n\u001b[0;32m---> 53\u001b[0m     img \u001b[39m=\u001b[39m call_plugin(\u001b[39m'\u001b[39;49m\u001b[39mimread\u001b[39;49m\u001b[39m'\u001b[39;49m, fname, plugin\u001b[39m=\u001b[39;49mplugin, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mplugin_args)\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(img, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/condaocr/lib/python3.9/site-packages/skimage/io/manage_plugins.py:207\u001b[0m, in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not find the plugin \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    205\u001b[0m                            (plugin, kind))\n\u001b[0;32m--> 207\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaocr/lib/python3.9/site-packages/skimage/io/_plugins/imageio_plugin.py:15\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m@wraps\u001b[39m(imageio_imread)\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(imageio_imread(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/miniconda3/envs/condaocr/lib/python3.9/site-packages/imageio/v2.py:226\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m imopen_args \u001b[39m=\u001b[39m decypher_format_arg(\u001b[39mformat\u001b[39m)\n\u001b[1;32m    224\u001b[0m imopen_args[\u001b[39m\"\u001b[39m\u001b[39mlegacy_mode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39;49m\u001b[39mri\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mimopen_args) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m    227\u001b[0m     result \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread(index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    229\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/condaocr/lib/python3.9/site-packages/imageio/core/imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     request\u001b[39m.\u001b[39mformat_hint \u001b[39m=\u001b[39m format_hint\n\u001b[1;32m    112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     request \u001b[39m=\u001b[39m Request(uri, io_mode, format_hint\u001b[39m=\u001b[39;49mformat_hint, extension\u001b[39m=\u001b[39;49mextension)\n\u001b[1;32m    115\u001b[0m source \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<bytes>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(uri, \u001b[39mbytes\u001b[39m) \u001b[39melse\u001b[39;00m uri\n\u001b[1;32m    117\u001b[0m \u001b[39m# fast-path based on plugin\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/condaocr/lib/python3.9/site-packages/imageio/core/request.py:247\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Request.Mode: \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[39m# Parse what was given\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_uri(uri)\n\u001b[1;32m    249\u001b[0m \u001b[39m# Set extension\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m extension \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/condaocr/lib/python3.9/site-packages/imageio/core/request.py:407\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m is_read_request:\n\u001b[1;32m    405\u001b[0m     \u001b[39m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(fn):\n\u001b[0;32m--> 407\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo such file: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m fn)\n\u001b[1;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     \u001b[39m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     dn \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(fn)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/Users/y.tahtah/Downloads/ecl_ocr/sports_scr/data/natation/ROI/CLIP_text_prompt/000014.png'"
     ]
    }
   ],
   "source": [
    "evaluate(data_path, path_tuples, dic_names, roi_path='ROI/', clip_text_prompt='CLIP_text_prompt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(data_path, path_tuples, dic_names, roi_path='ROI/', clip_visual_prompt='CLIP_visual_prompt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a25b912b07e4dd4585ccde04ffb04637057c446ad3642b0a9b78343cc072e7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
