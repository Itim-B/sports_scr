{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/said/anaconda3/envs/openmmlab/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/said/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "WARNING:easyocr.easyocr:CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "from preprocess import * \n",
    "from predict import *\n",
    "from utils import *\n",
    "from torchmetrics import WordErrorRate, CharErrorRate, MatchErrorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/said/courses/Projetinfo/sports_scr/data/champions/natation.txt\"\n",
    "dic_names = get_champions_names(data_path)\n",
    "scoreboard_path = \"../data/natation/ROI/CLIP_visual_prompt/scoreboard.png\"\n",
    "default_visual_prompt = Image.open(scoreboard_path)\n",
    "default_visual_prompt = np.array(default_visual_prompt)[:,:, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(path):\n",
    "    \"\"\"Returns ground truth data\n",
    "\n",
    "    Args:\n",
    "        path (str): path to the ground truth txt file\n",
    "\n",
    "    Returns:\n",
    "        list: list of the ground truth data\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        return [line.strip() for line in f.readlines()]\n",
    "    \n",
    "def compute_metrics(result, groundtruth):\n",
    "    wer = WordErrorRate()\n",
    "    cer = CharErrorRate()\n",
    "\n",
    "    word_error_rate = 0\n",
    "    character_error_rate = 0\n",
    "\n",
    "    for yhat, y in zip(result, groundtruth):\n",
    "        word_error_rate += wer(yhat, y)\n",
    "        character_error_rate += cer(yhat, y)\n",
    "\n",
    "    return word_error_rate/min(len(result), len(groundtruth)), character_error_rate/min(len(result), len(groundtruth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path =\"../data/champions/natation.txt\"\n",
    "dic_names = get_champions_names(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img, orientation, clip):\n",
    "    if clip:\n",
    "        modified_img = extract_roi_clipseg_visual(img, prompt=default_visual_prompt, thresh=0.5)\n",
    "        if orientation:\n",
    "            modified_img = correct_orientation(modified_img)\n",
    "        return modified_img\n",
    "    else:\n",
    "        if orientation:\n",
    "            modified_img = correct_orientation(modified_img)\n",
    "            return modified_img\n",
    "        else:\n",
    "            return np.array(Image.open(img))\n",
    "\n",
    "def evaluate(ocr_engine, orientation, clip):\n",
    "    total_wer, total_cer = 0, 0\n",
    "    img_paths = create_images_path_list(\"../data/natation\")\n",
    "    for img in img_paths:\n",
    "        processed_img = process_img(img, orientation, clip)\n",
    "\n",
    "        predictions = infer(ocr_engine, processed_img)\n",
    "        input_string = ' '.join(predictions)\n",
    "        result = extract_names_scores(input_string, dic_names, min_edit_distance=3)\n",
    "\n",
    "        groundtruth_path = img.split('.')\n",
    "        groundtruth_path[-1] = \".txt\"\n",
    "        groundtruth_path = '..' + ''.join(groundtruth_path[2:])\n",
    "        groundtruth = get_ground_truth(groundtruth_path)\n",
    "\n",
    "        try:\n",
    "            wer, cer = compute_metrics(result, groundtruth)\n",
    "        except:\n",
    "            wer, cer = 1, 1\n",
    "        total_wer += wer\n",
    "        total_cer += cer\n",
    "    return total_wer/len(img_paths), total_cer/len(img_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# docTR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctr_base_total_wer, doctr_base_total_cer = evaluate(ocr_engine='doctr', orientation=False, clip=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base + correction d'orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctr_orient_total_wer, doctr_orient_total_cer = evaluate(ocr_engine='doctr', orientation=True, clip=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP + correction d'orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
